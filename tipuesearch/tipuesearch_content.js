var tipuesearch = {"pages": [{"title": "A note of <i>A survey on Transfer Learning</i>","text": "A Survey on Transfer Learning<br/>Introduction<br/>Applied range<br/>knowledge transfer  or transfer learning would be desirable when it is expensive or impossible to recollect the needed training data and rebuild the models.<br/>Examples<br/><br/><br/>Web-document classification<br/>To classify a given Web document into several predefined categories. <br/>For example, the labeled examples may be the university webpages. But the newly created website may have different data features or data distributions. <br/><br/><br/>Data which outdate easily <br/>Example: indoor WiFi localization problems. We wish to adapt the localization model trained in one time period (the source domain) for a new time period (the target domain), or to adapt the localization model trained on a mobile device (the source domain) for a new mobile device (the target domain)<br/><br/><br/>The problem of sentiment classification<br/>To adapt a classification model that is trained on some products to help learn classification models for some other products<br/><br/><br/>Overview<br/>Brief History<br/>History<br/><br/><br/>Traditional machine learning algorithms: make predictions on the future data using statistical models that are trained on previously collected training data<br/><br/><br/>Semisupervised classification: much unlabeled data, little labeled data. Assume they are the same.<br/><br/><br/>Transfer Learning<br/><br/><br/>Motivation: People can intelligently apply knowledge learned previously to solve new problems<br/><br/><br/>Fundamental motivation: A NIPS-95 workshop on “Learning to Learn”<br/><br/><br/>Different names: learning to learn, life-long learning, knowledge transfer, inductive transfer, multitask learning, knowledge consolidation, context-sensitive learning, knowledge-based inductive bias, metalearning, and incremental/cumulative learning<br/><br/><br/>New definition: the ability of a system to recognize and apply knowledge and skills learned in previous tasks to novel tasks.<br/><br/>Difference between transfer learning and mutitask learning: transfer learning cares most about the target task, while multitask learning learning all of the source and target tasks simultaneously<br/><br/><br/><br/>Top venues: <br/><br/>data mining: ACM KDD, IEEE ICDM, and PKDD, for example<br/>machine learning: ICML, NIPS, ECML, AAAI, and IJCAI, for example<br/>applications of machine learning and data mining: ACM SIGIR, WWW, and ACL, for example<br/><br/><br/><br/>Notations and Definitions<br/>Definitions of “Domain” and “Task”<br/>A domain $D$ consists of two components: a feature space $\\mathcal{X}$ and a marginal probability distribution $P(X)$, where $X = \\{x_1, \\dots, x_n\\} \\in \\mathcal{X}$.<br/>A task consists of two components: a label space $\\mathcal{Y}$ and an objective predictive function $f(\\cdot)$.<br/>This survey only consider one source domain $\\mathcal{D}_S$, one target domain $\\mathcal{D}_T$ and usually $0 \\le N_T \\ll N_S$.<br/>Unified definition<br/>Transfer Learning: Given a source domain $\\mathcal{D}_S$ and learning task $\\mathcal{T}_S$, a target domain $\\mathcal{D}_T$ and learning task $\\mathcal{T}_T$, transfer learning aims to help improve the learning of the target predictive function $f_T(\\cdot)$ in $\\mathcal{D}_T$ using the knowledge in $\\mathcal{D}_S$ and $\\mathcal{T}_S$,where $\\mathcal{D}_S \\neq \\mathcal{D}_T$, or $\\mathcal{T}_S \\neq \\mathcal{T}_T$.<br/>A Categorization of Transfer Learning Techniques<br/>Three main research issues:<br/><br/>what to transfer<br/>how to transfer<br/>when to transfer<br/><br/>Three subsettings:<br/><br/>inductive transfer learning<br/>transductive transfer learning<br/>unsupervised transfer learning<br/><br/>inductive transfer learning<br/>The target task is different from the source task, no matter when the source and target domains are the same or not.<br/>Two cases:<br/>1. A lot of labeled data in the source domain are available.<br/>2. No labeled data in the source domain are available.<br/>transductive transfer learning<br/>The source and target tasks are the same, while the source and target domains are different.<br/>Two cases:<br/>1. $\\mathcal{X}_S \\neq \\mathcal{X}_T$.<br/>2. $\\mathcal{X}_S = \\mathcal{X}_T$ but $P(X_S) \\neq P(X_T)$.<br/>unsupervised transfer learning<br/>no labeled data available in both source and target domains in training.<br/>Inductive transfer learning<br/>Inductive transfer learning: Given a source domain $\\mathcal{D}_S$ and a learning task $\\mathcal{T}_S$, a target domain $\\mathcal{D}_T$ and a learning task $\\mathcal{T}_T$, inductive transfer learning aims to help improve the learning of the target predictive function $f_T(\\cdot)$ in $\\mathcal{D}_T$ using the knowledge in $\\mathcal{D}_S$ and $\\mathcal{T}_S$ where $\\mathcal{T}_S \\neq \\mathcal{T}_T$.<br/>Transferring Knowledge of Instances<br/>a boosting algorithm: TrAdaBoost<br/>Transferring Knowledge of Feature Representations","tags": "Note","url": "blog/180602/ASoTL.html"},
{"title": "Home Page","text": "欢迎来到 lan-qing’s site！<br/>This blog is build upon riteme.<br/>最近更新<br/><br/>Added note A note of A Survey on Transfer Learning<br/>copy from riteme<br/>","tags": "Home","url": "index.html"},
{"title": "关于","text": "关于<br/>整个都是从riteme那里抄来的。下面的都是riteme大神写的。希望以后我会改一些吧。<br/>### The sitegen.py<br/>使用 `Python 3` 编写的不清真站点生成器。<br/>参见左侧栏 [\ GitHub 项目\ ](https://github.com/riteme/riteme.github.io)。<br/><br/>需要的依赖：<br/><br/>* Python 3 (>= 3.4)<br/>* Python Markdown<br/>* Pygments (用于提供代码高亮)<br/>* Beautiful Soup 4<br/><br/>独立模块功能：<br/><br/>* `info`: 提取文档基本信息 (右上角)。<br/>* `navigater`: 辅助文件夹导航。<br/>* `parser`: Markdown 阶段预处理特殊语法。<br/>* `tag`: 标签生成。<br/>* `tipuesearch`: 生成 Tipuesearch 的搜索数据。<br/>* `tocer`: 提取并生成目录。<br/><br/>可执行工具：<br/><br/>* `pagegen.py`: 用于生成单个页面。<br/>* `sitegen.py`: 用于生成整个网站。<br/>* `setup.py`: 简单网站架设工具。<br/><br/>### The Material Design<br/>使用的是功能比较简单的 [Material Design Lite](http://getmdl.io/)。<br/><br/>### 数学公式<br/>使用 [MathJax](http://www.mathjax.org/) 和 [KaTeX](http://khan.github.io/KaTeX/)。<br/><br/>~~以后计划抛弃笨重的 MathJax，换用清真的 KaTeX。~~<br/>正在尝试 KaTeX......但现实很残酷，KaTeX 容错性实在不行，因此变成了浏览者可在 MathJax 和 KaTeX 之间二选一。<br/>实际上 KaTeX 能够无错渲染的文章真的不多......<br/><br/>### 站内搜索<br/>使用 [Tipuesearch](http://www.tipue.com/search/)。<br/><br/>Tipuesearch 有个缺点就是需要浏览器将搜索数据下载下来。而这个文件通常很大。以后可能会考虑换成其它的东西。<br/><br/>### 评论<br/>使用 [Gitment](https://github.com/imsun/gitment)。","tags": "About","url": "about.html"},
{"title": "友链","text": "友情链接","tags": "Friend Links","url": "links.html"},
{"title": "所有文章","text": "2018-6<br/><br/>A note of A Survey on Transfer Learning<br/>","tags": "Posts","url": "posts.html"},
{"title": "测试","text": "pagegen.py的试炼<br/>希望pagegen.py能正确工作。  <br/>常规Markdown测试<br/>h1<br/>h2<br/>h3<br/>h4<br/>h5<br/>h6<br/>上面是六级标题。  <br/><br/>上面是六级标题。<br/>这是一段引用  <br/><br/>很好，inline-code和Hello, world：<br/>#include <iostream><br/><br/>using namespace std;<br/><br/>int main(int argc, char *argv[]) {<br/>    cout << \ Hello, world!\  << endl;<br/><br/>    return 0;<br/>}<br/>别忘了Python：<br/>#!/usr/bin/env python3<br/><br/>if __name__ == \ __main__\ :<br/>    print(\ Hello, world!\ )<br/>Tab也可以直接代码<br/>Yeah!!!<br/>重要的话说三遍<br/>重要的话说三遍<br/>重要的话说三遍<br/>下划线是什么鬼<br/>打表A题：<br/><br/><br/><br/>NOI<br/>A<br/>B<br/>A + B<br/><br/><br/><br/><br/>1<br/>1<br/>2<br/>3<br/><br/><br/>2<br/>2<br/>2<br/>4<br/><br/><br/>3<br/>5<br/>5<br/>10<br/><br/><br/>4<br/>3<br/>4<br/>7<br/><br/><br/><br/><br/><br/><br/>列1<br/>列2<br/>列3<br/><br/><br/><br/><br/>233333333333333<br/>23333333<br/>233<br/><br/><br/><br/>脚注1？  <br/>GFM breaks!<br/>应该不在一行!<br/>应该不在一行!!<br/>应该不在一行!!!!!<br/>deleted<br/>inserted<br/>–smartpants—<br/>“a“‘b‘“c“‘d‘“e”“’<br/>Mathjax测试: $e^{ix} = \\cos x + i\\sin x$<br/>这个应该不得出问题......<br/>$$ \\sum_{i = 1}^{\\infty} i = - {1 \\over 12} \\tag{1.1} $$<br/>$$ a^2 + b^2 = c^2 \\Rightarrow \\triangle ABC\\text{是直角三角形} \\tag{1.2} $$<br/>$$<br/>\\begin{aligned}<br/>X_k & = \\sum^{n - 1}_{j = 0} x_ke^{-2\\pi ijk/n} \\\\<br/>    & = \\sum^{n - 1}_{j = 0} x_kw_n^{-jk}<br/>\\end{aligned}<br/>$$<br/>$$<br/>\\begin{aligned}<br/>x_k & = \\frac1n\\sum^{n - 1}_{j = 0} X_ke^{2\\pi ijk/n} \\\\<br/>    & = \\frac1n\\sum^{n - 1}_{j = 0} X_kw_n^{jk}<br/>\\end{aligned}<br/>$$<br/>$$ $$$$ $ $<br/>行内公式inline-math在此$ 233 \\neq 244 $233333<br/>特殊语法测试<br/>FBI Warning<br/>肯定有BUG<br/><br/>Markdown in it<br/>STRONG, inline-code.<br/><br/>中文<br/>Not Supported…<br/>乱搞<br/>233444<br/><br/>233<br/><br/>Goodbye!<br/><br/><br/><br/><br/>真的行吗...... ↩<br/><br/><br/>","tags": "test","url": "blog/1115/test.html"}]};