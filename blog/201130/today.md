---
title: Aistudio常规赛-论文引用网络节点分类 比赛记录
create: 2020.11.30
modified: 2020.11.30
tags: 
---
[TOC]
#### 背景
大概是在周四上课的时候，听到老师讲了一下有比赛。 当天回去我就连夜fork了baseline代码，跑了一遍。 大概发现和baseline差不多的样子，GCN的性能在0.68左右，GAT还要稍差一些。 当时榜单第一名大概是71.5。

#### 修改模型
结合之前对ResNet的理解，加上阅读了DeeperGCN这篇文章，我对PGL里面实现的DeeperGCN做了一个简单封装，跑了一下。 简单调参以后，提交上去评测以后acc是72.59，印象里比当时的第二名高了一个百分点以上。 我满意地睡觉了。

#### 继续修改模型
周五起来以后，调了调参数发现模型始终就是这个水平。 我觉得可能这个模型的上限也就是这样了，还需要继续改动模型架构。 借鉴Residual Attention Network这篇文章，我实现了一个把残差结构和注意力机制放在一起的网络结构。 这里注意力机制使用了GaAN。 周五下午实现了这个以后，第一次交上去结果就有0.73879。 但是后续不论怎么调参，结果始终没有提升。 周五晚上看到老师魔改了一个ResGAT出来，我感觉和我的差不多，就没有尝试。 （后续听说有同学把这个调到好高好高，羡慕。）

#### 放弃，抱大腿
周六早上再看榜单，发现我已经跌出前三名了。第一名是Paddle Baseline的一个模型。 我当时就想，看来是老师们看菜鸡互啄看不下去了，放了个baseline让我找找差距。 我当时有些绝望，开始找论文读。 想起老师之前讲的，百度自研的Unimp模型，我感觉可以一试。 没想到，把unimp模型运行起来花了我大半天的时间。 不过，在逐步排除错误的时候，对unimp的理解，对paddle框架的理解，以及对图神经网络的理解都有了很大提升。 Unimp模型的结果非常令我惊讶，在验证集上一度达到了0.761+的acc。 不过，交到测试集上的结果只有0.75803 。 后续调参都没有突破。

#### 最后的改动
周天的时候看到大家提交的结果都非常好，也让我感到了很大的压力。 这时候，我看着文件夹里之前的一排submission.csv，突然想到，能不能把它们利用起来呢？ 说做就做，就实现了一个简单的集成学习，使用的是绝对多数投票法。这个方法果然有了很大提升，经过几次尝试之后，acc达到了0.76401。

#### 总结
1. 可能是因为不太会调参，我感觉模型架构上的有效改进意义远大于不停地人肉搜参。但看到很多大佬调baseline模型仍然能拿到很好的成绩，我很惊讶，也希望大佬们能传授一下经验。
2. 后面才注意到比赛用的数据集是ogbn-arixv的子集，而unimp模型也是在ogbn-arixv数据集上刷新了sota的模型。不得不感叹一句，百度PGL团队，强。
3. 最后，再次感谢老师，班主任，助教，各位同学们的指导与陪伴，真的让我学到了很多有用的知识。
4. 有对细节或者其他东西感兴趣的朋友，欢迎讨论。但这个笔记就不要转载啦（写得这么差，应该也不会有人想要转吧）。
